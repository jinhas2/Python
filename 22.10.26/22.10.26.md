## AI의 기초

### Machine Learning

- 데이터를 많이 주고 기계한테 직접 찾게 함. → 알고리즘, 모델
- 데이터 사이언티스트 (리서치위주)
    - Data modeling
    - Data Algorithm
- 데이터 엔지니어

### 지도학습

- 문제와 정답제공 → features and labels
- 예측, 추정, 분류 → regression, forecast, classification

### 비지도학습

- 문제만 제공 → feature
- 패턴/구조 발견, 그룹화 → anomaly(변칙검색), clustering(군집)

### 강화학습

- 보상 제공, 인과관계가 중요
- 게임(알파고), 로봇

## Data

kaggle 

국가통계포털  

### 회귀 분석 Regression

관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한 뒤 적합도를 측정해내는 방법. 

- **MEA (Mean absolute error)** : 절대평균오차, 오차를 다 합쳐서 평균을 낸다.
- **MSE (Mean squared error)** : 예측값과 실제값의 차이의 제곱을 평균. but 너무 크거나 작은 데이터가 있으면 overflow가 발생할 수 있음.
- **RMSE (Root mean squared error)** : 원래 범위로 다시 떨어뜨린다.
- **MAE (Mean absolute error)**
- **R2 (R squared, 결정계수)** : 0.74로 나온 경우 25%정도 오류가 난다는 것을 알 수 있다.

### 분류분석 Classification

관찰된 범주형 변수들에 대해 두 변수 사이의 모형을 구한 뒤 적합도를 측정해 내는 분석 방법.

### 평가지표

![image](https://user-images.githubusercontent.com/95389515/198827795-d7db4de8-4fbb-44ed-a336-f3566ed1a304.png)

일단 예측이 맞으면 True, 예측이 틀리면 False → 잘 맞췄을 때 True 

**Accuracy(CA, 정확도)** : 전체 중 실제 True를 True라고, 실제 False를 False라고 예측한 것의 비율 

**Precision(정밀도)** : 모델이 True라고 분류한 것 중에서 모델이 True라고 예측한 것의 비율

**Recall(재현율)** : 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율

**F1 score** : Precision과 Recall의 조화평균 

**ROC curve** : 여러 임계치들을 기준으로 Recall-Fallout의 변화를 시각화한 것 

**AUC(Area under curve)** : ROC 그래프 아래의 면적 

![image](https://user-images.githubusercontent.com/95389515/198827841-83b0db71-eab9-4c53-bc1d-ff9641bb92d2.png)

![image](https://user-images.githubusercontent.com/95389515/198827852-3f602fc8-f069-477e-b7ce-3cda9416e7ee.png)

### 핵심정리

![image](https://user-images.githubusercontent.com/95389515/198827805-dda2f574-5b48-4631-8ff6-7ceb6b70483c.png)
