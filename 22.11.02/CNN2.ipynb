{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62fbb1b3-5dda-444f-925b-1eae419760b6",
      "metadata": {
        "id": "62fbb1b3-5dda-444f-925b-1eae419760b6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil  # <- 이걸 사용한다. (쉐 명령어를 사용하기 위해서)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44661cc6-b6ff-4e0c-a781-750e6ad78bed",
      "metadata": {
        "id": "44661cc6-b6ff-4e0c-a781-750e6ad78bed"
      },
      "outputs": [],
      "source": [
        "# Original Data Path\n",
        "original_dataset_dir = './datasets/train'\n",
        "\n",
        "# 이미지를 3등분한다.\n",
        "# Small Dataset Path\n",
        "base_dir = './datasets/cats_and_dogs_small' # datasets의 위치에 경로를 하나 만들어 준다.\n",
        "\n",
        "if os.path.exists(base_dir):  # 해당되는 경로가 있는가 없는가를 체크한다. 만약 해당되는 경로가 있으면 지운다.\n",
        "    shutil.rmtree(base_dir) # 해당되는 경로를 삭제해준다.\n",
        "os.mkdir(base_dir) # 해당되는 경로의 디렉토리를 만들어 준다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce6b8e82-e4d2-4c99-babf-563936818577",
      "metadata": {
        "id": "ce6b8e82-e4d2-4c99-babf-563936818577"
      },
      "source": [
        "* 6개의 폴더를 추가로 만들어준다.\n",
        "* Train data, Validation data, Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "536193a5-ec64-4cfe-9916-b9899b717c67",
      "metadata": {
        "id": "536193a5-ec64-4cfe-9916-b9899b717c67"
      },
      "outputs": [],
      "source": [
        "# Train, Validation, Test data\n",
        "\n",
        "# 학습용 경로를 만든다.\n",
        "train_dir = os.path.join(base_dir, 'train') # base_dir 경로 뒤에 tarin이라는 폴더를 생성한다.\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eaed445-af20-4ac3-9645-efb0e8c21d99",
      "metadata": {
        "id": "2eaed445-af20-4ac3-9645-efb0e8c21d99"
      },
      "outputs": [],
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "\n",
        "os.mkdir(train_cats_dir)\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "os.mkdir(validation_cats_dir)\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "os.mkdir(test_cats_dir)\n",
        "os.mkdir(test_dogs_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49e70102-8bde-40ca-b997-c0981886874e",
      "metadata": {
        "id": "49e70102-8bde-40ca-b997-c0981886874e"
      },
      "source": [
        "* 필요한 경로 6개를 설정해준다.\n",
        "* 이미지를 처리 할때, 경로를 지정해준다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c502f457-b206-4e54-b23b-670f8e3ec25f",
      "metadata": {
        "id": "c502f457-b206-4e54-b23b-670f8e3ec25f"
      },
      "source": [
        "## file copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0c95e4-d805-4ec8-be9e-ea241a75cd9f",
      "metadata": {
        "id": "ff0c95e4-d805-4ec8-be9e-ea241a75cd9f"
      },
      "outputs": [],
      "source": [
        "# file copy\n",
        "\n",
        "# 배열을 하나 만든다.\n",
        "# fnames = [] # 파이썬에서의 리스트 객체가 된다.\n",
        "\n",
        "# for i in range(1000): # for문은 0부터 999까지 반복을 한다.\n",
        "#     filename = 'cat.{}.jpg'.format(i)\n",
        "#     fnames.append(filename) # 반복할때 마다 리스트 객체를 넣어준다.\n",
        "    \n",
        "# print(fnames)\n",
        "\n",
        "# cat train data copy\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname) # 원본 경로를 잡은 것이다.\n",
        "    dst = os.path.join(train_cats_dir, fname) # 대상 경로(학습을 시킬 cat경로이다.)\n",
        "    shutil.copyfile(src, dst) # 원본 경로에서 대상 경로로 카피를 하라.\n",
        "\n",
        "# dog train data copy\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname) \n",
        "    dst = os.path.join(train_dogs_dir, fname) \n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "# 학습용 데이터 1000개씩 확보를 한 것이다.\n",
        "print('---------------------------- Test dataset copy completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2190da-5d67-426b-9c5d-e12a181cfdaf",
      "metadata": {
        "id": "ae2190da-5d67-426b-9c5d-e12a181cfdaf",
        "outputId": "fae5e476-48e4-4c12-a22f-eea622e5077f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------- Validation dataset copy completed\n"
          ]
        }
      ],
      "source": [
        "# cat validation data copy\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname) \n",
        "    dst = os.path.join(validation_cats_dir, fname) \n",
        "    shutil.copyfile(src, dst) \n",
        "    \n",
        "# dog validation data copy\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname) \n",
        "    dst = os.path.join(validation_dogs_dir, fname) \n",
        "    shutil.copyfile(src, dst)\n",
        "print('---------------------------- Validation dataset copy completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a7be12e-8a60-4f91-879e-b132eb428773",
      "metadata": {
        "id": "1a7be12e-8a60-4f91-879e-b132eb428773",
        "outputId": "5a30aef2-56af-48a5-ce61-df8fcd9bc7b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------- Test dataset copy completed\n"
          ]
        }
      ],
      "source": [
        "# cat test data copy\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname) \n",
        "    dst = os.path.join(test_cats_dir, fname) \n",
        "    shutil.copyfile(src, dst) \n",
        "    \n",
        "# dog test data copy\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname) \n",
        "    dst = os.path.join(test_dogs_dir, fname) \n",
        "    shutil.copyfile(src, dst)\n",
        "print('---------------------------- Test dataset copy completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a2a42bd-8e7c-42fa-bae9-bd26c94c82c0",
      "metadata": {
        "id": "1a2a42bd-8e7c-42fa-bae9-bd26c94c82c0",
        "outputId": "0885cfd4-4a2d-4620-eda4-9105101215dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train cat images:  1000\n",
            "Train dog images:  1000\n",
            "Validation cat images:  500\n",
            "Validation dog images:  500\n",
            "Test cat images:  500\n",
            "Test dog images:  500\n"
          ]
        }
      ],
      "source": [
        "print('Train cat images: ', len(os.listdir(train_cats_dir))) # os.listdir 지정되는 경로 안에 파일의 개수를 알 수 있다. 그럼 전체 파일의 목록이 나온다.\n",
        "print('Train dog images: ', len(os.listdir(train_dogs_dir)))\n",
        "\n",
        "print('Validation cat images: ', len(os.listdir(validation_cats_dir)))\n",
        "print('Validation dog images: ', len(os.listdir(validation_dogs_dir)))\n",
        "\n",
        "print('Test cat images: ', len(os.listdir(test_cats_dir)))\n",
        "print('Test dog images: ', len(os.listdir(test_dogs_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92952e21-18a4-4911-8641-333c15e31aef",
      "metadata": {
        "id": "92952e21-18a4-4911-8641-333c15e31aef",
        "outputId": "0aad295d-7edf-4957-a674-3c755222360c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build network\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation = 'relu'))\n",
        "model.add(layers.Dense(1, activation = 'sigmoid')) # 이진분류 문제가 되었다.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2b5511-10d8-4974-ad96-a60549bfebb2",
      "metadata": {
        "id": "ae2b5511-10d8-4974-ad96-a60549bfebb2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(optimizer = 'rmsprop',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0696c86-bec3-4fbf-914f-00fe15b6f937",
      "metadata": {
        "id": "c0696c86-bec3-4fbf-914f-00fe15b6f937"
      },
      "source": [
        "1) 데이터를 전처리 해줄 필요가 있고\n",
        "2) 데이터를 늘려줄 필요가 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76346751-03bb-410b-86cb-99c4efd31dca",
      "metadata": {
        "id": "76346751-03bb-410b-86cb-99c4efd31dca"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5cf02ca-2c32-46c0-8d0c-1874a2f0e81e",
      "metadata": {
        "id": "a5cf02ca-2c32-46c0-8d0c-1874a2f0e81e",
        "outputId": "a78efffd-5195-4daa-eb40-54506b4e7956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data Preprocdssing (이미지의 스케일을 조절해준다.)\n",
        "\n",
        "# Image Scaling\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 턴서로 바꾸어주는 역할을 한다.\n",
        "train_datagen =  ImageDataGenerator(rescale = 1./255) # 스케일을 재조정해준다.\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)  # 비율로서 조정을 한다.\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(               # 타깃 디렉토리를 지정해주어야 한다.\n",
        "                                        train_dir,\n",
        "                                        target_size = (150, 150),\n",
        "                                        batch_size = 20,\n",
        "                                        class_mode = 'binary') # 둘중하나를 지정하는 거라서 binary라고 해준다.\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "                                        test_dir,\n",
        "                                        target_size = (150, 150),\n",
        "                                        batch_size = 20,\n",
        "                                        class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f9920be-33ed-480b-8439-2a3d7d81c9b6",
      "metadata": {
        "id": "1f9920be-33ed-480b-8439-2a3d7d81c9b6",
        "outputId": "42eb0925-32d6-40b9-e981-1ad2a39f2bc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Data Size:  (20, 150, 150, 3)\n",
            "Batch Label Size:  (20,)\n"
          ]
        }
      ],
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print('Batch Data Size: ', data_batch.shape)\n",
        "    print('Batch Label Size: ', labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe892527-9812-49b2-8cd6-bbcb17c141a1",
      "metadata": {
        "id": "fe892527-9812-49b2-8cd6-bbcb17c141a1",
        "outputId": "f2f13555-1e1c-46ed-bd9f-0206759df8d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\kcw0331\\AppData\\Local\\Temp\\2\\ipykernel_2144\\1326091177.py:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "100/100 [==============================] - 52s 519ms/step - loss: 0.7938 - accuracy: 0.5280 - val_loss: 0.9480 - val_accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 0.6894 - accuracy: 0.5865 - val_loss: 0.6759 - val_accuracy: 0.5680\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 0.6539 - accuracy: 0.6550 - val_loss: 0.6462 - val_accuracy: 0.6370\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 50s 495ms/step - loss: 0.5998 - accuracy: 0.6880 - val_loss: 0.5986 - val_accuracy: 0.6730\n",
            "Epoch 5/30\n",
            " 73/100 [====================>.........] - ETA: 11s - loss: 0.5620 - accuracy: 0.7281"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator( # 여기서는 fit_generator를 사용해준다.\n",
        "    train_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 30, # 총 반복 횟수를 30번을 가진다.\n",
        "    validation_data = test_generator, # validation_generator를 아직 안 만들어서 test_generator를 사용한다.\n",
        "    validation_steps = 50 # 50개 단위로 검증을 한다.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e3c717-1e98-4eaf-a1c2-2db6a857b323",
      "metadata": {
        "id": "30e3c717-1e98-4eaf-a1c2-2db6a857b323"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(    \n",
        "      rescale=1./255,    \n",
        "      rotation_range=40,    \n",
        "      width_shift_range=0.2,    \n",
        "      height_shift_range=0.2,    \n",
        "      shear_range=0.2,    \n",
        "      zoom_range=0.2,    \n",
        "      horizontal_flip=True,)\n",
        "\n",
        "# 검증 데이터는 증식되어서는 안 됩니다!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(        \n",
        "      # 타깃 디렉터리        \n",
        "      train_dir,        \n",
        "      # 모든 이미지를 150 × 150 크기로 바꿉니다        \n",
        "      target_size=(150, 150),        \n",
        "      batch_size=32,        \n",
        "      # binary_crossentropy 손실을 사용하기 때문에 이진 레이블을 만들어야 합니다        \n",
        "      class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(        \n",
        "      validation_dir,        \n",
        "      target_size=(150, 150),        \n",
        "      batch_size=32,        \n",
        "      class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(      \n",
        "      train_generator,      \n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "azureml_py38"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}